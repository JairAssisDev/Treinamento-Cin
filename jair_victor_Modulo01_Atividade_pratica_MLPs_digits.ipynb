{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairAssisDev/Treinamento-Cin/blob/main/jair_victor_Modulo01_Atividade_pratica_MLPs_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificando digítos com MLPs\n",
        "\n",
        "Vamos utilizar um modelo MLP para realizar a classificação de imagens que possuem digítos (0-9).\n",
        "\n",
        "Para o teste utilizaremos o dataset digits do sklearn (https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)\n",
        "\n",
        "O dataset é composto por imagens 8x8 em tons de cinza, cada uma com sua label correspondente (0-9).\n",
        "\n",
        "\n",
        "```OBS: Quando pedido, realize a operação na célula correspondente atribuindo o resultado na variável indicada. Não altere os nomes das variáveis utilizadas. Você pode utilizar celular adicionais para realizar testes, utilizando variaveis auxiliares para visualizar resultados intermediários.```"
      ],
      "metadata": {
        "id": "3eOFRXwE0QKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 - Importando as bibliotecas e carregando o dataset\n",
        "\n",
        "Utilizamos o módulo datasets do sklearn para carregar os dados a partir da função load_digits(return_X_y=True).\n",
        "\n",
        "Passamos o parâmetro return_X_y com True para que a função retorne os exemplos e as anotações em variaveis separadas, atribuimos o resultado na variavel images e target, respectivamente. As variáveis serão retornadas como numpy.*ndarray*"
      ],
      "metadata": {
        "id": "Qs4SsGMJ0uEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUQvqij4z8bv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "images, target = datasets.load_digits(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 1.1 - Verifique as dimensões das variáveis images e target\n",
        "## Substitua as linhas abaixo para retornar o resultado\n",
        "\n",
        "shape_images = images.shape\n",
        "shape_target = images.shape\n",
        "\n",
        "print(shape_images)\n",
        "print(shape_target)"
      ],
      "metadata": {
        "id": "4Mdn4OAU2n71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4bd08dd-56a9-4b6e-df9e-48e9b1650658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 1.2 - Quantos exemplos possui o dataset digits?\n",
        "dataset_size = images.shape[0]\n",
        "\n",
        "print(dataset_size)"
      ],
      "metadata": {
        "id": "Kj_M9u8Z4FFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a7dd56-6010-41cd-8c94-5c4fafc01558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 - Visualizando os exemplos\n",
        "\n",
        "Utilizando a biblioteca matplotlib, vamos tentar visualizar alguns dos dados disponíveis no dataset."
      ],
      "metadata": {
        "id": "1gN3gOdg4wER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, prediction in zip(axes, images, target):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {prediction}\")"
      ],
      "metadata": {
        "id": "fUomUtW148xZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "7d95f16d-77fa-4ade-877f-a0d232b16f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 - Separando as partições\n",
        "\n",
        "Utilize a função train_test_split do sklearn para separar as partições em dois conjuntos (treino e teste). Utilizaremos o conjunto de treino para ajustar o modelo e o conjunto de teste para avaliar o desempenho do nosso modelo.\n",
        "\n",
        "Utilize a função de forma que o conjunto de treino possua 70% dos dados e o conjunto de teste possua 30%.\n",
        "\n",
        "Referência train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split"
      ],
      "metadata": {
        "id": "dey-3Riy5ZdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3.1 Utilize a função train_test_split para obter as partições\n",
        "# Atribua o resultado nas variaveis acima\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "\n",
        "# 3.2 Compute o tamanho de cada partição, atribuindo o valor nas variaveis abaixo\n",
        "train_size = _\n",
        "test_size  = _\n",
        "\n",
        "print(train_size, test_size)"
      ],
      "metadata": {
        "id": "DvJO41ta5_b_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717a6508-6fa9-45d8-f842-d79da844642a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure(1000x300) Figure(1000x300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 - Inicializando e treinando o modelo\n",
        "\n",
        "Agora vamos carregar e treinar o modelo utilizando os dados da partição de treino.\n",
        "\n",
        "Vamos utilizar a classe MLPClassifier do sklearn para instanciar a nossa rede (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
        "\n",
        "Crie um modelo que contenha 3 camadas escondidas de dimensão (50,20,10) utilizando a função de ativação relu, otimizador adam, e learning rate 0.001. (Utilize max_iter=300)"
      ],
      "metadata": {
        "id": "hu0FsBvX7k57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 - Inicialize o modelo instanciando o classificador com o sklearn e atribua a variavel network\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "network = MLPClassifier(hidden_layer_sizes=(50, 20, 10), activation='relu', solver='adam', learning_rate_init=0.001, max_iter=300)\n",
        "\n",
        "print(network.activation, network.solver,\n",
        "      network.learning_rate_init, network.hidden_layer_sizes)"
      ],
      "metadata": {
        "id": "QKhgcVs379tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b44214-972e-4278-a68d-8f1a40d78bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu adam 0.001 (50, 20, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 - Utilize a função fit para realizar o treinamento com as partições X_train e y_train\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "network.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8qwPS8sfac7E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8c2b3068-a569-41e6-f938-c67dfe4650ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 - Avaliando o resultado\n",
        "\n",
        "Utilize a função predict, para realizar as predições com o conjunto X_test"
      ],
      "metadata": {
        "id": "AnqmJke3-0Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 - Utilize a função predict a partir do modelo treinado\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "predictions = network.predict(X_test)\n",
        "\n",
        "print(\n",
        "    f\"Classification report for classifier {network}:\\n\"\n",
        "    f\"{metrics.classification_report(y_test, predictions)}\\n\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZSZFppnR_PMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar os parâmetros da rede a partir do atributo coefs_.\n",
        "Da mesma forma, podemos acessar o valor de bias de cada neurônio acessando o atributo intercepts_.\n",
        "\n",
        "Acesse os atributos coefs_ e intercepts_ da rede para verificar a dimensão dos conjuntos de pesos da rede criada. Utilize esses valores para calcular o numero de parâmetros treinaivéis que a nossa rede possui.\n"
      ],
      "metadata": {
        "id": "QSCIErIHB_-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = network.coefs_\n",
        "bias    = network.intercepts_\n",
        "\n",
        "# 5.2 - Compute o numero de parametros e substitua o valor da variável abaixo com o numero de parametros do modelo\n",
        "\n",
        "parameters_number = sum([coef_matrix.size for coef_matrix in weights]) + sum([bias_vector.size for bias_vector in bias])\n",
        "\n",
        "print(parameters_number)"
      ],
      "metadata": {
        "id": "bWGuZAF7AHf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc3faad-5f7e-45c8-f7dc-376e82d87865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 - Testando em um dataset externo\n",
        "\n",
        "Treinamos e testamos nosso modelo em um unico dataset. Na prática, vamos querer aplicar o nosso modelo em diferentes conjuntos e dados.\n",
        "\n",
        "Para simular este caso, vamos carregar alguns imagens do dataset MNIST. Podemos acessar o MNIST pelo PyTorch, utlizando o módulo datasets.MNIST.\n",
        "\n",
        "O MNIST também é um dataset para classificação de digitos, porém, o dataset é composto por imagens em tons de cinza de dimensão 28x28 com anotações entre 0-9.\n",
        "\n",
        "As células seguintes são utilizadas para baixar a partição de teste do dataset localmente, carregar os exemplos utilizando a classe dataloader do PyTorch.\n",
        "\n",
        "Podemos manipular o dataloader como um objeto do tipo iterator, desta forma, podemos obter os exemplos utilizando a função next() do python; ou qualquer outra função compativel com iterators.\n",
        "\n",
        "Utilizamos o batch_size igual a 10, que significa que para cada iteração do dataloader obtemos 10 imagens do conjunto de teste.\n",
        "\n",
        "As imagens e labels são retornadas ao final do processo utilizando as variaveis mnist_images e mnist_label."
      ],
      "metadata": {
        "id": "-lGp8gW3IHnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "test_ds = datasets.MNIST(root = \".\", train = False,\n",
        "                         download = True, transform = transform)\n",
        "\n",
        "test_dl = data.DataLoader(\n",
        "    test_ds, batch_size=50, shuffle=True,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "mnist_test_images, mnist_test_labels = next(iter(test_dl))\n",
        "\n",
        "mnist_test_images  = mnist_test_images.numpy()\n",
        "mnist_test_labels  = mnist_test_labels.numpy()"
      ],
      "metadata": {
        "id": "VO7Ij0U3IMCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimindo a dimensão da imagem, podemos perceber que a representação utilizada pelo PyTorch não corresponde a utilizada pelo nosso modelo.\n",
        "\n",
        "O PyTorch representa os exemplos do mnist como (B, C, H, W), onde B é o tamanho do batch (numero de imagens), C o número de canais, H a altura da imagem e W a largura da imagem."
      ],
      "metadata": {
        "id": "oNAjrZv_MIHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_test_images.shape)"
      ],
      "metadata": {
        "id": "X27nL-EsJJk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dd80e3-bc2c-4902-d013-120e381b8618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar essa imagem no nosso modelo, precisamos redimensionar os dados para 8x8 (mesmo tamanho utilizado pela nossa rede). Em seguida, devemos converter essa entrada para um vetor de dimensão (B, 64), transformando nossa imagem 8x8 é um vetor unidimensional.\n",
        "\n",
        "-> Utilize a função resize do opencv (https://learnopencv.com/image-resizing-with-opencv/) para redimensionar nossos exemplos e em seguida aplique as funções da biblioteca numpy para obter o vetor nas dimensões esperada pelo modelo.\n",
        "\n",
        "Dica 01: Temos um conjunto de B imagens na variavel mnist_images, itere sobre a variavel e realize as operações para cada imagem individualmente.\n",
        "\n",
        "Dica 02: Remova a dimensão 1 que representa C antes do resize. O opencv utiliza a representação (H,W,C) - altura, largura, canais. Podendo omitir o valor dos canais quando C=1 (i.e., (H,W)). Utilize o numpy.squeeze (https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html)\n",
        "\n",
        "Dica 03: Para transformar a imagem em um vetor unidimensional utilize as funções flatten ou reshape do numpy"
      ],
      "metadata": {
        "id": "SyqcJjadMe7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_images = np.squeeze(mnist_test_images, axis=1)\n",
        "\n",
        "# 6.1 - remova a dimensão extra que representa os canais\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "\n",
        "resized_images = []\n",
        "for img in squeezed_images:\n",
        "    resized_img = cv2.resize(img, (8, 8))\n",
        "    flattened_img = resized_img.flatten()\n",
        "    resized_images.append(flattened_img)\n",
        "\n",
        "resized_images = np.array(resized_images)\n",
        "print(squeezed_images.shape)"
      ],
      "metadata": {
        "id": "GX1s2zMmMFz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b48a71-93fd-4246-a168-cac292a0ec1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resized_images = []\n",
        "\n",
        "# 6.2 - redimensione as imagens para o tamanho 8x8\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "for img in squeezed_images:\n",
        "    resized_img = cv2.resize(img, (8, 8))\n",
        "    resized_images.append(resized_img)\n",
        "\n",
        "resized_images = np.array(resized_images)\n",
        "print(resized_images.shape)"
      ],
      "metadata": {
        "id": "e5joP8dePS6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823c9624-d972-4d8b-f0ec-3c68f015543b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforme as imagens 8x8 em vetores de tamanho 64\n",
        "mnist_transformed = resized_images.reshape(resized_images.shape[0], -1)\n",
        "\n",
        "print(mnist_transformed.shape)\n"
      ],
      "metadata": {
        "id": "VnPr4hFDPyy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54de0aee-7147-471c-96ec-ed77329fbed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Execute as próximas células para visualizar as imagens antes e depois das transformações"
      ],
      "metadata": {
        "id": "9Jrvw0WtRQIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as imagens 28x28 antes da transformação\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, squeezed_images, mnist_test_labels):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "liZztWxDQ4bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "180ca050-d834-4312-8a20-b2ce301e78bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAADSCAYAAAAi0d0oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYfElEQVR4nO3da1BV59nG8XvXoOCRGg6OTsEh6oijdhoPcYgEDZnSeIoi6qSThk4dnCRtR5naHEyiVE3wEIyTqokxUw/tB5sY1NZTo1UUGwto1MQISFESY6NAFGs0QRzW++F99Y3lfpCF62GzN//fjB9ysVnrluFxe2WROz7HcRwBAAAAAI99z98DAAAAAAhOlA0AAAAAVlA2AAAAAFhB2QAAAABgBWUDAAAAgBWUDQAAAABWUDYAAAAAWEHZAAAAAGAFZQMAAACAFZQND1RUVIjP55PXXnvNs2vm5eWJz+eTvLw8z64J+BPnBLgzzgnQNJyVwNFmy8a6devE5/PJ4cOH/T2KNefOnZOpU6dKeHi4dO3aVR577DE5ffq0v8dCAGkL52Tjxo1y//33S2hoqERGRsr06dOlurra32MhgLSFc8L7CbwQ7GeltLRUMjMzJSEhQUJDQ8Xn80lFRYW/x/K7Nls2gt3XX38to0ePlv3798ucOXPkd7/7nRw9elSSkpLkq6++8vd4QKvw5ptvyuOPPy7du3eXZcuWSUZGhmzcuFGSk5Pl22+/9fd4QKvA+wnQNIcOHZI33nhDrly5IvHx8f4ep9W4x98DwI5Vq1ZJWVmZFBYWyrBhw0RE5NFHH5WBAwdKTk6OvPrqq36eEPCv69evy5w5c+Shhx6S3bt3i8/nExGRhIQEGT9+vKxZs0Z+/etf+3lKwP94PwGaZsKECVJTUyNdunSR1157TY4dO+bvkVoFnmw04vr16zJ37lwZMmSIdOvWTTp16iSJiYmyb98+4+e8/vrrEhsbK2FhYZKUlCQnTpxo8JqSkhJJS0uT7t27S2hoqAwdOlT+8pe/3HGea9euSUlJSZN+xGPTpk0ybNiwW28MIiL9+/eX5ORkeffdd+/4+UBTBeo5OXHihNTU1Mi0adNuFQ0RkXHjxknnzp1l48aNd7wX0FSBek5EeD9Bywrks9K9e3fp0qXLHV/X1lA2GvGf//xH3nnnHRk1apQsXrxYsrKypKqqSlJSUtS2umHDBnnjjTfkl7/8pbzwwgty4sQJefjhh+XChQu3XvPpp5/KiBEjpLi4WJ5//nnJycmRTp06ycSJE2Xz5s2NzlNYWCjx8fGyYsWKRl9XX18vH3/8sQwdOrTBx4YPHy7l5eVy5cqVpn0RgDsI1HNSW1srIiJhYWENPhYWFiZHjx6V+vr6JnwFgDsL1HPC+wlaWqCeFTTCaaPWrl3riIhTVFRkfM2NGzec2tra27JLly450dHRzi9+8Ytb2ZkzZxwRccLCwpwvvvjiVl5QUOCIiJOZmXkrS05OdgYNGuR8++23t7L6+nonISHB6du3761s3759jog4+/bta5DNmzev0d9bVVWVIyLO/PnzG3xs5cqVjog4JSUljV4DcJzgPyc+n8+ZPn36bXlJSYkjIo6IONXV1Y1eA3Cc4D8nvJ/AK8F8Vv7b0qVLHRFxzpw54+rzghFPNhrRrl07ad++vYj877/duXjxoty4cUOGDh0qH330UYPXT5w4UXr16nXrn4cPHy4PPPCA7NixQ0RELl68KHv37pWpU6fKlStXpLq6Wqqrq+Wrr76SlJQUKSsrk3PnzhnnGTVqlDiOI1lZWY3O/c0334iISIcOHRp8LDQ09LbXAHcrUM9JRESETJ06VdavXy85OTly+vRpyc/Pl2nTpklISIiIcE7gnUA9J7yfoKUF6lmBGWXjDtavXy+DBw+W0NBQuffeeyUyMlK2b98uly9fbvDavn37Nsj69et3a+3Zv/71L3EcR15++WWJjIy87de8efNERKSysvKuZ775YyE3f0zku25u2NF+dARorkA8JyIiq1evljFjxsjs2bPlvvvuk4ceekgGDRok48ePFxGRzp07e3IfQCQwzwnvJ/CHQDwrMGMbVSP+9Kc/yc9//nOZOHGi/Pa3v5WoqChp166dZGdnS3l5uevr3fz579mzZ0tKSor6mj59+tzVzCL/+x8odejQQb788ssGH7uZ9ezZ867vA4gE7jkREenWrZts3bpVPv/8c6moqJDY2FiJjY2VhIQEiYyMlPDwcE/uAwTqOeH9BC0tUM8KzCgbjdi0aZPExcVJbm7ubdtqbjbh/1ZWVtYgO3XqlPTu3VtEROLi4kREJCQkRB555BHvB/4/3/ve92TQoEHq/zSnoKBA4uLi2JYAzwTqOfmumJgYiYmJERGRmpoaOXLkiEyePLlF7o22IVDPCe8naGmBelZgxo9RNaJdu3YiIuI4zq2soKBADh06pL5+y5Ytt/3cX2FhoRQUFMijjz4qIiJRUVEyatQoWb16tfpviaqqqhqdx836tbS0NCkqKrrtDaK0tFT27t0rU6ZMuePnA00VyOdE88ILL8iNGzckMzOzWZ8PaAL5nPB+gpYUyGcFujb/ZOMPf/iD7Nq1q0E+c+ZMGTdunOTm5sqkSZNk7NixcubMGXnrrbdkwIAB8vXXXzf4nD59+sjIkSPl6aefltraWlm+fLnce++98uyzz956zcqVK2XkyJEyaNAgycjIkLi4OLlw4YIcOnRIvvjiCzl+/Lhx1sLCQhk9erTMmzfvjv+h0jPPPCNr1qyRsWPHyuzZsyUkJESWLVsm0dHR8pvf/KbpXyBAgvecLFq0SE6cOCEPPPCA3HPPPbJlyxb54IMPZOHChbf9PwWApgjWc8L7CbwWrGfl8uXL8vvf/15ERP7xj3+IiMiKFSskPDxcwsPD5Ve/+lVTvjzBxz9LsPzv5vo106+zZ8869fX1zquvvurExsY6HTp0cH70ox8527Ztc9LT053Y2Nhb17q5fm3p0qVOTk6O84Mf/MDp0KGDk5iY6Bw/frzBvcvLy50nn3zS6dGjhxMSEuL06tXLGTdunLNp06Zbr/Fi/drZs2edtLQ0p2vXrk7nzp2dcePGOWVlZc39kqENCvZzsm3bNmf48OFOly5dnI4dOzojRoxw3n333bv5kqENCvZz4ji8n8AbwX5Wbs6k/fru7G2Nz3G+85wKAAAAADzCf7MBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCCsgEAAADACsoGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMAKygYAAAAAKygbAAAAAKygbAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCCsgEAAADACsoGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMAKygYAAAAAKygbAAAAAKygbAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCCsgEAAADACsoGAAAAACvu8fcAgebq1atqnp2dreb5+flqnpGRYbxHVVWVmvt8PjWfNWuW8VoAAABtyZkzZ9Q8OTnZ9ef88Ic/VPNjx465nqut4skGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMAKygYAAAAAK9hG5dKYMWPUPDU1Vc0jIiLUfPbs2cZ7VFZWqrlpG9Xf/vY3Nf/jH//oaiYAQMupr69Xc9OWm+joaDWPiooy3iMkJMT1XECgM22WqqioMH6O6e9Yn3zyiZrn5uaquenvg20ZTzYAAAAAWEHZAAAAAGAFZQMAAACAFZQNAAAAAFZQNgAAAABYwTYql/bv36/mVVVVav7WW2+puWnjlIiI4zhq3r9/fzXftWuXmps2lFy4cEHNIyMjjTMBAJrn6NGjar5kyRI1//Of/+zq+llZWcaPzZ0719W1TK5cuaLmps2KpveZxx9/XM2nTZvWvMEAy0x/JzNtk0NDPNkAAAAAYAVlAwAAAIAVlA0AAAAAVlA2AAAAAFhB2QAAAABgBduoPPLkk0+qeWlpqZoPGDDAeK0NGzaouWkbVX5+vpqnp6er+ZgxY9R8586dah4REaHmgFsHDhxQ823btqn50qVLjdfy+XyezGSSlJSk5vPnz1fzxMREm+OgFamtrVXzFStWqPlLL73k6jrh4eFqXlNTo+Znz55Vcy/V1dWp+alTp9T82LFjar59+3Y1N23seuWVV9S8Xbt2ag6IiBQWFvp7BHwHTzYAAAAAWEHZAAAAAGAFZQMAAACAFZQNAAAAAFZQNgAAAABY4XMcx/H3EIEkNTVVzbds2aLmQ4YMUfNly5YZ7+HVVpvc3Fw1f+qpp9R8zpw5aj5r1ixP5kHgMm2iOXnypJq///77ar5y5Uo1N23ZaeyPp+joaDWvrKw0fo4bpnt///vfV/PnnntOzZ999llP5kHL++yzz9Q8KytLzdevX6/mpu+lKVOmqLnpz+jQ0FA1N50fEfP2QdsOHjyo5uPHj1fzy5cvq/mLL76o5gsWLGjeYGgTRo4cqeYffvih62uZtocWFRWpeVhYmOt7BDuebAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCCbVQGCxcuVPO5c+equWlbwZtvvqnmXm2cag7TphPTRq19+/apeXx8vFcjoZWoqKhQ81WrVql5Tk6OxWlEHnvsMePHFi9erOam34PJ4cOH1dy0Bcfn86n5j3/8YzXfuXOnq3nQ8srLy9X86aefVvPdu3e7uv6kSZPU3LQxMJgtWbJEzU3b3MLDw9XctAmoT58+zZoLwcXLbVTt27dXc9P59dcGuNaMJxsAAAAArKBsAAAAALCCsgEAAADACsoGAAAAACsoGwAAAACsuMffA/jbrl271Ny0dSomJkbN8/Ly1DwiIqJZc9m0YMECNT9y5Iiap6amunp9x44dmzcY/G7+/Plqvm7dOjU3bWYyue+++9R8w4YNaj5ixAhX1xcR6du3r5qfPn1azefNm+f6Hhq2s7V+dXV1av7yyy+r+Z49e9Q8MjJSzbOzs9U8LS2tCdO1DZMnT1bz559/Xs0vX76s5suXL1fzFStWNGsuwCQsLEzNu3fv3sKTBC6ebAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCizWyjKi4uVvP09HQ1N23ZMW2vao1bp0xMm1QyMjLU/KmnnlLz3NxcNX/iiSeaNxhazMMPP6zmBw8e9OT6U6ZMUfNXXnlFzU1bqrxk+r4sKChwdR3TnxmLFi1yPRNa1qZNm9R848aNrq4zZMgQNZ8+fbrrmdqabt26eXKdsrIyT66DwHbhwgU1v3jxomf3CA0NVfPOnTt7do9gx5MNAAAAAFZQNgAAAABYQdkAAAAAYAVlAwAAAIAVlA0AAAAAVgTdNqqrV6+q+YsvvqjmlZWVap6UlKTm/fv3b95gAWDGjBlq/tJLL6n55s2b1ZxtVC3v3//+t5rPmjVLzfPy8lxdv3fv3mp++vRpV9dpCQsXLlTzf/7zn66u4ziOmps2ebVv397V9dHy9uzZ4+r1Y8aMUfP33nvPi3HapKKiIk+uExMT48l1ENiOHj2q5iUlJZ7do0ePHmo+cOBAz+4R7HiyAQAAAMAKygYAAAAAKygbAAAAAKygbAAAAACwgrIBAAAAwIqg20aVnZ2t5lu3blXz+Ph4Nd+wYYNnMwW61NRUNV+zZk0LTwKTqqoqNX///ffV3OfzqfnYsWPVfNGiRc0b7C7V1dUZP7Z//341P3DggJqbfs9umb7WaP3Kyspcvd60YSwsLMyLcdqkTz75xJPrmP6sQtvSGjcioiGebAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALAi6LZRmbbvOI7j6vUxMTGezRToTF87U47A1bFjRzWvrKxU8wEDBnhy37y8PDXfsWOH8XNycnI8ubdbpk11mZmZLTwJ3MrPz3f1+oSEBEuTtF1r165Vc9P7Sf/+/dV84sSJXo2EALZu3Tp/j4Am4MkGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMAKygYAAAAAKygbAAAAAKwI2NW3ubm5al5aWqrmkydPVvP4+HjPZgpWPp/PVY7A9d5776n55s2b1dyr1bfFxcVqfv36dePnmL7/evbsqebXrl1T85qamsaH+y/p6emuXo/WIzQ0VM1ra2vVvF+/fjbHCWoffvihmldUVKg57zNorXr16uXvEQIeTzYAAAAAWEHZAAAAAGAFZQMAAACAFZQNAAAAAFZQNgAAAABYEbDbqKqrq9XccRw179+/v81xgkJVVZWar169Ws2joqJsjgMXTFuhDh06pOYTJkxQc9P3QF1dnZp//PHHTZiu+Tp16mT82Ny5c9U8IyNDzUePHq3mbrdRRUREuHo9Wo+f/vSnar527Vo1//vf/67mpvOD/5eVlaXmps1fJo888ogH0wDNN2PGDH+PEPB4sgEAAADACsoGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMCKgN1GZeLz+dR80qRJLTxJ4Nm8ebOam76mqampNseBCyEhIWo+fPhwNT9//ryar1q1Ss2vXbvWvMGaaNiwYWqelJTk+loffPCBmh8/ftzVdXr37q3mTzzxhNuR0Ep069bN1euLi4vV/OLFi2revXt31zMFCtMWqZkzZ6r57t271dz0fvLggw+q+fz585swHYJdUVGRmpeXl3t2jz59+qj50KFDPbtHW8WTDQAAAABWUDYAAAAAWEHZAAAAAGAFZQMAAACAFZQNAAAAAFYE3TYqx3H8PUKrd/XqVTVfvny5msfExKj5ggULvBoJrcQzzzzj7xHu2q5du9TctAXHJBi+FrhdVlaWmps28e3Zs0fNk5OT1dz0vRcdHX3n4Vo509apt99+29V1TBvytm7dqubh4eGuro/g9Omnn6r5pUuXPLtHXFycmvfs2dOze7RVPNkAAAAAYAVlAwAAAIAVlA0AAAAAVlA2AAAAAFhB2QAAAABgRdBtozJtnDl58qSa33///TbHaZV+9rOfqXlpaamab9q0Sc0jIiI8mwlw68qVK2qen5/vyfV79+7tyXXQenTt2lXNTZuQnnvuOTU3bZ1KSkpS83feeUfNhwwZouZhYWFq3hwHDx5U89raWjWfPn26mn/22Weu7vvggw+q+fbt29W8W7durq6P4PTNN9+o+ZIlS6zfOzMz0/o92iqebAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALAiYLdRmTYhOY6j5ps3b1bzlJQUNY+MjGzeYH5g2oySnp6u5levXlVz09apSZMmNW8wwKKsrCw1/+ijjzy5flpamifXQes3ePBgNc/JyVHz48ePq/mpU6fUPDExUc3j4uLUvH379mreHCUlJWpu2txo0qVLFzU3nZPXX39dzdk6hcb89a9/VXPT9zECA082AAAAAFhB2QAAAABgBWUDAAAAgBWUDQAAAABWUDYAAAAAWBGw26hSU1Nd5Vu2bFHzzz//XM2XLVum5qatIl46cOCAmpt+D8uXL1dz07YRtk4hGFRXV3tynWHDhnlyHQSfAQMGqLlp69TevXvVfO3atWpeV1en5jt27GjCdHcnNjZWzU0zmbYeDhw40LOZALdb0ry0c+dONTdtLUXT8WQDAAAAgBWUDQAAAABWUDYAAAAAWEHZAAAAAGAFZQMAAACAFQG7jcpk5syZam7aOnX48GE1T0pKUnPHcdTctAXr5MmTal5aWqrmjd0jKipKzWfNmqXmc+bMUfOIiAjjvYFAYTonptzkJz/5iRfjoA3p3Lmzmk+YMMFVXl9fr+aXLl1Sc9MWrMb069dPzTt06KDmpvPTpUsX1/cG3Bo8eLCa9+jRQ83Pnz/v2b0LCgo8uxZux5MNAAAAAFZQNgAAAABYQdkAAAAAYAVlAwAAAIAVlA0AAAAAVvgct6tbAlR1dbWaHzlyRM2zs7PV/MCBA2ru8/nUfMaMGWpeXFys5iIiiYmJap6RkaHmMTExxmsBgayurs74scmTJ6v59u3bXd3jyy+/VHPT9jcAQMt6++231XzBggVqfu7cOdf32Llzp5qnpKS4vhZux5MNAAAAAFZQNgAAAABYQdkAAAAAYAVlAwAAAIAVlA0AAAAAVrSZbVQAAs/58+eNH+vVq5cn92AbFQAA9vBkAwAAAIAVlA0AAAAAVlA2AAAAAFhB2QAAAABgBWUDAAAAgBWUDQAAAABWUDYAAAAAWEHZAAAAAGAFZQMAAACAFZQNAAAAAFZQNgAAAABYcY+/BwCAlrB48WI1j4iIaOFJAABoO3iyAQAAAMAKygYAAAAAKygbAAAAAKygbAAAAACwgrIBAAAAwAqf4ziOv4cAAAAAEHx4sgEAAADACsoGAAAAACsoGwAAAACsoGwAAAAAsIKyAQAAAMAKygYAAAAAKygbAAAAAKygbAAAAACwgrIBAAAAwArKBgAAAAArKBsAAAAArKBsAAAAALCCsgEAAADACsoGAAAAACsoGwAAAACs+B8w6FBnJj6PZwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as imagens 8x8\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, mnist_transformed, mnist_test_labels):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "PmwydNYNLAKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "bb88b64a-90f5-41da-934a-23fec8caebe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos passar agora nossas imagens transformadas para que o modelo realize as predições\n",
        "\n",
        "-> Utilize a função predict para obter os resultados a partir da variavel network, utilizando como parametro nossa variavel mnist_transformed"
      ],
      "metadata": {
        "id": "sGKpkkP5RoTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.5 - Utilize a função predict a partir do modelo treinado\n",
        "\n",
        "# INSIRA O CÓDIGO AQUI\n",
        "predictions_mnist = network.predict(mnist_transformed)\n",
        "\n",
        "print(\n",
        "    f\"Classification report for classifier {network}:\\n\"\n",
        "    f\"{metrics.classification_report(mnist_test_labels, predictions_mnist)}\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "L7Nmvc4QRlhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2038bf18-f67f-4a65-812d-aabb56f85d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for classifier MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.25      0.29         4\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.50      0.14      0.22         7\n",
            "           3       0.00      0.00      0.00         8\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00        10\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.14      0.33      0.20         3\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.14      0.83      0.23         6\n",
            "\n",
            "    accuracy                           0.16        50\n",
            "   macro avg       0.11      0.16      0.09        50\n",
            "weighted avg       0.12      0.16      0.09        50\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Avalie o resultado anterior. O modelo manteve a acurácia?"
      ],
      "metadata": {
        "id": "jG3N1o6tS6P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra (Opcional)\n",
        "\n",
        "Na célula abaixo carregamos um conjunto adicional de treino do mnist.\n",
        "Tente treinar o mesmo modelo anterior utilizando esse novo conjunto e avalie o resultado final.\n",
        "\n",
        "Teste o treinamento com imagens 8x8 e também com 28x28. O resultado é alterado utilizando o mesmo modelo?\n",
        "\n",
        "Teste diferentes tamanhos de imagens, diferentes arquiteturas e diferentes métodos de resize para avaliar as mudanças dos resultados.\n"
      ],
      "metadata": {
        "id": "nBwCG7wfUMGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = datasets.MNIST(root = \".\", train = False,\n",
        "                         download = True, transform = transform)\n",
        "\n",
        "train_dl = data.DataLoader(train_ds, batch_size=1000,\n",
        "          shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "mnist_train_images, mnist_train_labels = next(iter(train_dl))\n",
        "\n",
        "mnist_train_images = mnist_train_images.numpy()\n",
        "mnist_train_labels  = mnist_train_labels.numpy()"
      ],
      "metadata": {
        "id": "PmjmKsm8TxgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# E.1 - Transforme os dados\n",
        "\n",
        "# E.2 - Crie e treine o modelo com o conjunto de treino\n",
        "\n",
        "# E.3 - Avalie o resultado utilizando o conjunto de teste\n"
      ],
      "metadata": {
        "id": "iElBNfDTUiKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}